{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAGAS Synthetic Data Generation with LangGraph Agent Graph\n",
        "\n",
        "This notebook demonstrates how to reproduce RAGAS Synthetic Data Generation steps using a LangGraph Agent Graph instead of the Knowledge Graph approach. The implementation leverages the Evol-Instruct method to generate synthetic data with three types of evolution:\n",
        "\n",
        "1. **Simple Evolution**: Making questions more specific and detailed\n",
        "2. **Multi-Context Evolution**: Creating questions that require information from multiple sources\n",
        "3. **Reasoning Evolution**: Generating questions that require complex reasoning and analysis\n",
        "\n",
        "## Features\n",
        "\n",
        "- **LangGraph Workflow**: Uses LangGraph's stateful agent system for orchestration\n",
        "- **Evol-Instruct Method**: Implements question evolution strategies\n",
        "- **Multiple Evolution Types**: Handles simple, multi-context, and reasoning evolution\n",
        "- **Context Retrieval**: Automatically retrieves relevant contexts for questions\n",
        "- **Answer Generation**: Generates comprehensive answers based on retrieved contexts\n",
        "\n",
        "## Output Format\n",
        "\n",
        "The system generates three main outputs:\n",
        "- **Evolved Questions**: List of questions with IDs and evolution types\n",
        "- **Answers**: Question-answer pairs with IDs\n",
        "- **Contexts**: Relevant contexts for each question\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Environment setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import getpass\n",
        "from typing import List, Dict\n",
        "import pandas as pd\n",
        "\n",
        "# Set up environment variables\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "# Set project name\n",
        "from uuid import uuid4\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"RAGAS-LangGraph-SDG-{uuid4().hex[0:8]}\"\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded 64 documents\n",
            "üìÑ Document sources: ['data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf', 'data/howpeopleuseai.pdf']\n",
            "\n",
            "üìã Sample document preview:\n",
            "   Title: How People Use ChatGPT\n",
            "   Pages: 64\n",
            "   Content length: 1672 characters\n",
            "   Content preview: NBER WORKING PAPER SERIES\n",
            "HOW PEOPLE USE CHATGPT\n",
            "Aaron Chatterji\n",
            "Thomas Cunningham\n",
            "David J. Deming\n",
            "Zoe Hitzig\n",
            "Christopher Ong\n",
            "Carl Yan Shan\n",
            "Kevin Wadman\n",
            "Working Paper 34255\n",
            "http://www.nber.org/papers/...\n"
          ]
        }
      ],
      "source": [
        "# Load documents using LangChain document loaders\n",
        "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
        "\n",
        "# Load PDF documents from the data directory\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(docs)} documents\")\n",
        "print(f\"üìÑ Document sources: {[doc.metadata.get('source', 'Unknown') for doc in docs]}\")\n",
        "\n",
        "# Display sample document info\n",
        "if docs:\n",
        "    sample_doc = docs[0]\n",
        "    print(f\"\\nüìã Sample document preview:\")\n",
        "    print(f\"   Title: {sample_doc.metadata.get('title', 'N/A')}\")\n",
        "    print(f\"   Pages: {sample_doc.metadata.get('total_pages', 'N/A')}\")\n",
        "    print(f\"   Content length: {len(sample_doc.page_content)} characters\")\n",
        "    print(f\"   Content preview: {sample_doc.page_content[:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the LangGraph SDG System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ RagasLangGraphSDG system initialized!\n",
            "üìä Configuration:\n",
            "   - LLM Model: gpt-4o-mini\n",
            "   - Embedding Model: text-embedding-3-small\n",
            "   - Chunk Size: 1000\n",
            "   - Chunk Overlap: 100\n"
          ]
        }
      ],
      "source": [
        "# Import our custom LangGraph SDG system\n",
        "from ragas_langgraph_sdg import RagasLangGraphSDG\n",
        "\n",
        "# Initialize the SDG system with custom parameters\n",
        "sdg_system = RagasLangGraphSDG(\n",
        "    llm_model=\"gpt-4o-mini\",  # Use GPT-4o mini for cost efficiency\n",
        "    embedding_model=\"text-embedding-3-small\",  # Efficient embedding model\n",
        "    chunk_size=1000,  # Reasonable chunk size for processing\n",
        "    chunk_overlap=100  # Good overlap for context preservation\n",
        ")\n",
        "\n",
        "print(\"‚úÖ RagasLangGraphSDG system initialized!\")\n",
        "print(f\"üìä Configuration:\")\n",
        "print(f\"   - LLM Model: gpt-4o-mini\")\n",
        "print(f\"   - Embedding Model: text-embedding-3-small\")\n",
        "print(f\"   - Chunk Size: 1000\")\n",
        "print(f\"   - Chunk Overlap: 100\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Synthetic Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting synthetic data generation...\n",
            "This will use the Evol-Instruct method with three evolution strategies:\n",
            "1. Simple Evolution - Making questions more specific\n",
            "2. Multi-Context Evolution - Questions requiring multiple sources\n",
            "3. Reasoning Evolution - Questions requiring complex reasoning\n",
            "\n",
            "üöÄ Starting synthetic data generation...\n",
            "üìÑ Preparing documents...\n",
            "‚úÖ Prepared 155 document chunks\n",
            "‚ùì Generating simple questions...\n",
            "‚úÖ Generated 15 simple questions\n",
            "üîÑ Applying simple evolution...\n",
            "‚úÖ Applied simple evolution to 15 questions\n",
            "üîÑ Applying multi-context evolution...\n",
            "‚úÖ Applied multi-context evolution to 15 questions\n",
            "üîÑ Applying reasoning evolution...\n",
            "‚úÖ Applied reasoning evolution to 15 questions\n",
            "üìö Generating contexts...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/powertothefuture/Documents/aimakerspace/AIE8/07_Synthetic_Data_Generation_and_LangSmith/ragas_langgraph_sdg.py:347: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  relevant_docs = retriever.get_relevant_documents(evolved_q.question)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Generated contexts for 45 questions\n",
            "üí¨ Generating answers...\n",
            "‚úÖ Generated answers for 45 questions\n",
            "‚úÖ Synthetic data generation completed!\n",
            "üìä Generated 45 evolved questions\n",
            "üìä Generated 45 answers\n",
            "üìä Generated 45 contexts\n",
            "\n",
            "üéâ Synthetic data generation completed!\n",
            "üìä Results summary:\n",
            "   - Evolved Questions: 45\n",
            "   - Answers: 45\n",
            "   - Contexts: 45\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic data using the LangGraph workflow\n",
        "print(\"üöÄ Starting synthetic data generation...\")\n",
        "print(\"This will use the Evol-Instruct method with three evolution strategies:\")\n",
        "print(\"1. Simple Evolution - Making questions more specific\")\n",
        "print(\"2. Multi-Context Evolution - Questions requiring multiple sources\")\n",
        "print(\"3. Reasoning Evolution - Questions requiring complex reasoning\")\n",
        "print()\n",
        "\n",
        "# Run the generation process\n",
        "synthetic_data = sdg_system.generate_synthetic_data(docs)\n",
        "\n",
        "print(\"\\nüéâ Synthetic data generation completed!\")\n",
        "print(f\"üìä Results summary:\")\n",
        "print(f\"   - Evolved Questions: {len(synthetic_data['evolved_questions'])}\")\n",
        "print(f\"   - Answers: {len(synthetic_data['answers'])}\")\n",
        "print(f\"   - Contexts: {len(synthetic_data['contexts'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã EVOLVED QUESTIONS ANALYSIS\n",
            "==================================================\n",
            "\n",
            "üîÑ Evolution Type Distribution:\n",
            "   simple: 15 questions\n",
            "   multi_context: 15 questions\n",
            "   reasoning: 15 questions\n",
            "\n",
            "üìù Sample Questions by Evolution Type:\n",
            "\n",
            "üîπ SIMPLE EVOLUTION:\n",
            "   Q: Could you provide the names of the authors and their affiliations for the working paper titled \"How People Use ChatGPT,\" as well as any relevant publication details such as the date of release and the journal or platform where it was published?\n",
            "   Original: Who are the authors of the working paper titled \"How People Use ChatGPT\"?\n",
            "\n",
            "   Q: Which specific institution is responsible for publishing the working paper series referenced in the document, and what is the title or focus of that particular series?\n",
            "   Original: What institution published the working paper series mentioned in the document?\n",
            "\n",
            "\n",
            "üîπ MULTI_CONTEXT EVOLUTION:\n",
            "   Q: Based on the insights provided in the working paper titled \"How People Use ChatGPT,\" compare the authors' perspectives on user engagement with ChatGPT to the findings on its impact on communication styles. How do the authors' backgrounds influence their interpretations of these aspects?\n",
            "   Original: Who are the authors of the working paper titled \"How People Use ChatGPT\"?\n",
            "\n",
            "   Q: How does the institution that published the working paper series compare to other organizations mentioned in the document in terms of their research focus and contributions to the field?\n",
            "   Original: What institution published the working paper series mentioned in the document?\n",
            "\n",
            "\n",
            "üîπ REASONING EVOLUTION:\n",
            "   Q: Considering the authors of the working paper titled \"How People Use ChatGPT,\" analyze how their backgrounds and expertise might influence the perspectives presented in the paper. How do their individual contributions shape the overall findings, and what implications do these findings have for our understanding of user interactions with AI technologies? Furthermore, compare their conclusions with existing literature on AI usage to evaluate any shifts in perception or new insights that emerge from this paper.\n",
            "   Original: Who are the authors of the working paper titled \"How People Use ChatGPT\"?\n",
            "\n",
            "   Q: How does the institution that published the working paper series contribute to the broader academic discourse on the topic discussed in the document, and what implications does its reputation have on the perceived validity of the findings presented? In your analysis, consider how the institution's previous research outputs compare to those of similar organizations and how this influences the credibility and impact of the series within the field.\n",
            "   Original: What institution published the working paper series mentioned in the document?\n",
            "\n",
            "\n",
            "üìä DATA QUALITY METRICS\n",
            "==================================================\n",
            "üìè Average Question Length: 313.6 characters\n",
            "üìè Average Answer Length: 1934.4 characters\n",
            "üìè Average Context Length: 2691.8 characters\n",
            "\n",
            "üîç Data Completeness:\n",
            "   Questions: 45\n",
            "   Answers: 45 (missing: 0)\n",
            "   Contexts: 45 (missing: 0)\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrames for easier analysis\n",
        "questions_df = pd.DataFrame(synthetic_data['evolved_questions'])\n",
        "answers_df = pd.DataFrame(synthetic_data['answers'])\n",
        "contexts_df = pd.DataFrame(synthetic_data['contexts'])\n",
        "\n",
        "print(\"üìã EVOLVED QUESTIONS ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Analyze evolution types\n",
        "evolution_counts = questions_df['evolution_type'].value_counts()\n",
        "print(f\"\\nüîÑ Evolution Type Distribution:\")\n",
        "for evolution_type, count in evolution_counts.items():\n",
        "    print(f\"   {evolution_type}: {count} questions\")\n",
        "\n",
        "print(f\"\\nüìù Sample Questions by Evolution Type:\")\n",
        "\n",
        "# Show examples of each evolution type\n",
        "for evolution_type in questions_df['evolution_type'].unique():\n",
        "    sample_questions = questions_df[questions_df['evolution_type'] == evolution_type].head(2)\n",
        "    print(f\"\\nüîπ {evolution_type.upper()} EVOLUTION:\")\n",
        "    for idx, row in sample_questions.iterrows():\n",
        "        print(f\"   Q: {row['question']}\")\n",
        "        if row['original_question']:\n",
        "            print(f\"   Original: {row['original_question']}\")\n",
        "        print()\n",
        "\n",
        "print(\"\\nüìä DATA QUALITY METRICS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Calculate some basic metrics\n",
        "avg_question_length = questions_df['question'].str.len().mean()\n",
        "avg_answer_length = answers_df['answer'].str.len().mean()\n",
        "avg_context_length = contexts_df['context'].str.len().mean()\n",
        "\n",
        "print(f\"üìè Average Question Length: {avg_question_length:.1f} characters\")\n",
        "print(f\"üìè Average Answer Length: {avg_answer_length:.1f} characters\")\n",
        "print(f\"üìè Average Context Length: {avg_context_length:.1f} characters\")\n",
        "\n",
        "# Check for missing data\n",
        "missing_answers = len(answers_df) - len(questions_df)\n",
        "missing_contexts = len(contexts_df) - len(questions_df)\n",
        "\n",
        "print(f\"\\nüîç Data Completeness:\")\n",
        "print(f\"   Questions: {len(questions_df)}\")\n",
        "print(f\"   Answers: {len(answers_df)} (missing: {missing_answers})\")\n",
        "print(f\"   Contexts: {len(contexts_df)} (missing: {missing_contexts})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Complete Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã COMPLETE SYNTHETIC DATASET\n",
            "================================================================================\n",
            "\n",
            "üìù COMPLETE EXAMPLES (showing first 3):\n",
            "================================================================================\n",
            "\n",
            "üîπ EXAMPLE 1 - SIMPLE EVOLUTION\n",
            "ID: 0bc6555f-92e9-4dc4-93a7-4ad67c21aa35\n",
            "Question: Could you provide the names of the authors and their affiliations for the working paper titled \"How People Use ChatGPT,\" as well as any relevant publication details such as the date of release and the journal or platform where it was published?\n",
            "Original: Who are the authors of the working paper titled \"How People Use ChatGPT\"?\n",
            "Answer: The working paper titled \"How People Use ChatGPT\" is authored by the following individuals:\n",
            "\n",
            "- Aaron Chatterji\n",
            "- Thomas Cunningham\n",
            "- David J. Deming\n",
            "- Zoe Hitzig\n",
            "- Christopher Ong\n",
            "- Carl Yan Shan\n",
            "- Ke...\n",
            "Context: NBER WORKING PAPER SERIES\n",
            "HOW PEOPLE USE CHATGPT\n",
            "Aaron Chatterji\n",
            "Thomas Cunningham\n",
            "David J. Deming\n",
            "Zoe Hitzig\n",
            "Christopher Ong\n",
            "Carl Yan Shan\n",
            "Kevin Wadman\n",
            "Working Paper 34255\n",
            "http://www.nber.org/papers/...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üîπ EXAMPLE 2 - SIMPLE EVOLUTION\n",
            "ID: 0484691b-6a2a-4548-99fb-f6399801ebc2\n",
            "Question: Which specific institution is responsible for publishing the working paper series referenced in the document, and what is the title or focus of that particular series?\n",
            "Original: What institution published the working paper series mentioned in the document?\n",
            "Answer: The specific institution responsible for publishing the working paper series referenced in the document is the National Bureau of Economic Research (NBER). The title or focus of that particular series...\n",
            "Context: Economic Research.\n",
            "At least one co-author has disclosed additional relationships of potential relevance for this research. \n",
            "Further information is available online at http://www.nber.org/papers/w34255...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üîπ EXAMPLE 3 - SIMPLE EVOLUTION\n",
            "ID: 703beeba-8459-4cdc-9f6b-dc9162eff9d1\n",
            "Question: What is the exact date and any relevant details regarding the approval of the working paper by the Harvard Institutional Review Board (IRB), including the IRB protocol number and any conditions or stipulations that were attached to the approval?\n",
            "Original: When was the working paper approved by Harvard IRB?\n",
            "Answer: The working paper titled \"HOW PEOPLE USE CHATGPT\" by Aaron Chatterji and co-authors was approved by the Harvard Institutional Review Board (IRB) under protocol number IRB25-0983. The approval date is ...\n",
            "Context: Economic Research.\n",
            "At least one co-author has disclosed additional relationships of potential relevance for this research. \n",
            "Further information is available online at http://www.nber.org/papers/w34255...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìä TOTAL DATASET SIZE: 45 complete examples\n"
          ]
        }
      ],
      "source": [
        "# Display the complete synthetic dataset\n",
        "print(\"üìã COMPLETE SYNTHETIC DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create a combined view\n",
        "combined_data = []\n",
        "\n",
        "for _, question_row in questions_df.iterrows():\n",
        "    question_id = question_row['id']\n",
        "    \n",
        "    # Find corresponding answer and context\n",
        "    answer_row = answers_df[answers_df['question_id'] == question_id]\n",
        "    context_row = contexts_df[contexts_df['question_id'] == question_id]\n",
        "    \n",
        "    combined_item = {\n",
        "        'id': question_id,\n",
        "        'evolution_type': question_row['evolution_type'],\n",
        "        'question': question_row['question'],\n",
        "        'original_question': question_row.get('original_question', ''),\n",
        "        'answer': answer_row['answer'].iloc[0] if not answer_row.empty else 'No answer',\n",
        "        'context': context_row['context'].iloc[0] if not context_row.empty else 'No context'\n",
        "    }\n",
        "    combined_data.append(combined_item)\n",
        "\n",
        "# Display first few complete examples\n",
        "print(f\"\\nüìù COMPLETE EXAMPLES (showing first 3):\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, item in enumerate(combined_data[:3], 1):\n",
        "    print(f\"\\nüîπ EXAMPLE {i} - {item['evolution_type'].upper()} EVOLUTION\")\n",
        "    print(f\"ID: {item['id']}\")\n",
        "    print(f\"Question: {item['question']}\")\n",
        "    if item['original_question']:\n",
        "        print(f\"Original: {item['original_question']}\")\n",
        "    print(f\"Answer: {item['answer'][:200]}...\" if len(item['answer']) > 200 else f\"Answer: {item['answer']}\")\n",
        "    print(f\"Context: {item['context'][:200]}...\" if len(item['context']) > 200 else f\"Context: {item['context']}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\nüìä TOTAL DATASET SIZE: {len(combined_data)} complete examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Exported to JSON: synthetic_data_output/langgraph_sdg_results_20251005_172617.json\n",
            "‚úÖ Exported questions to: synthetic_data_output/evolved_questions.csv\n",
            "‚úÖ Exported answers to: synthetic_data_output/answers.csv\n",
            "‚úÖ Exported contexts to: synthetic_data_output/contexts.csv\n",
            "‚úÖ Exported complete dataset to: synthetic_data_output/complete_dataset.csv\n",
            "\n",
            "üìÅ All files saved in: synthetic_data_output/\n",
            "üìä Dataset contains 45 complete question-answer-context triplets\n"
          ]
        }
      ],
      "source": [
        "# Export the synthetic data to various formats for further use\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Create export directory\n",
        "import os\n",
        "export_dir = \"synthetic_data_output\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "# Export to JSON\n",
        "json_filename = f\"{export_dir}/langgraph_sdg_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(json_filename, 'w') as f:\n",
        "    json.dump(synthetic_data, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Exported to JSON: {json_filename}\")\n",
        "\n",
        "# Export individual components to CSV\n",
        "questions_df.to_csv(f\"{export_dir}/evolved_questions.csv\", index=False)\n",
        "answers_df.to_csv(f\"{export_dir}/answers.csv\", index=False)\n",
        "contexts_df.to_csv(f\"{export_dir}/contexts.csv\", index=False)\n",
        "\n",
        "print(f\"‚úÖ Exported questions to: {export_dir}/evolved_questions.csv\")\n",
        "print(f\"‚úÖ Exported answers to: {export_dir}/answers.csv\")\n",
        "print(f\"‚úÖ Exported contexts to: {export_dir}/contexts.csv\")\n",
        "\n",
        "# Export combined dataset\n",
        "combined_df = pd.DataFrame(combined_data)\n",
        "combined_df.to_csv(f\"{export_dir}/complete_dataset.csv\", index=False)\n",
        "print(f\"‚úÖ Exported complete dataset to: {export_dir}/complete_dataset.csv\")\n",
        "\n",
        "print(f\"\\nüìÅ All files saved in: {export_dir}/\")\n",
        "print(f\"üìä Dataset contains {len(combined_data)} complete question-answer-context triplets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This implementation successfully reproduces RAGAS Synthetic Data Generation using a LangGraph Agent Graph approach with the following key features:\n",
        "\n",
        "### ‚úÖ **Completed Requirements**\n",
        "\n",
        "1. **LangGraph Agent Graph**: Uses LangGraph's stateful workflow system instead of Knowledge Graphs\n",
        "2. **Evol-Instruct Method**: Implements three evolution strategies:\n",
        "   - **Simple Evolution**: Makes questions more specific and detailed\n",
        "   - **Multi-Context Evolution**: Creates questions requiring information from multiple sources\n",
        "   - **Reasoning Evolution**: Generates questions requiring complex reasoning and analysis\n",
        "3. **Input Handling**: Takes a list of LangChain Documents as input\n",
        "4. **Output Format**: Produces the required three output types:\n",
        "   - List of evolved questions with IDs and evolution types\n",
        "   - List of question-answer pairs with IDs\n",
        "   - List of question-context pairs with IDs\n",
        "\n",
        "### üîß **Technical Implementation**\n",
        "\n",
        "- **Workflow Orchestration**: LangGraph manages the entire pipeline from document preparation to final output\n",
        "- **Agent-Based Architecture**: Specialized agents handle different tasks (question generation, evolution, context retrieval, answer generation)\n",
        "- **Vector-Based Context Retrieval**: Uses Qdrant vectorstore for efficient context retrieval\n",
        "- **Modular Design**: Easy to extend with additional evolution strategies or agents\n",
        "\n",
        "### üìä **Generated Data Quality**\n",
        "\n",
        "- **Diverse Question Types**: Covers simple factual questions to complex reasoning challenges\n",
        "- **Comprehensive Contexts**: Retrieves relevant document chunks for each question\n",
        "- **Accurate Answers**: Generates answers based on retrieved contexts\n",
        "- **Complete Dataset**: All questions have corresponding answers and contexts\n",
        "\n",
        "This approach provides a flexible, scalable alternative to RAGAS's Knowledge Graph method while maintaining the quality and diversity of synthetic data generation.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
